# Haoyang Huang (黄浩洋)

[Google Scholar](https://scholar.google.com/citations?user=nIS66toAAAAJ&hl=en) \| [LinkedIn](https://www.linkedin.com/in/%E6%B5%A9%E6%B4%8B-%E9%BB%84-77a59016a/)

### <span style="color: #ff0000;">We are currently seeking highly motivated researchers and interns to join us for unified multimodal models: huanghaoyang.ocean@jd.com (work) or hhy338189@gmail.com (personal).</span>

Haoyang Huang is currently a senior expert at the Image and Multimodal Lab of JD Discovery Academy, leading research on unified multimodal foundation models. He holds a master's degree from Peking University and has won numerous top global data mining competition awards, as well as the Kaggle Master title. At Microsoft Research Asia, he focused on multimodal and multilingual foundation models, being one of the earliest researchers to develop multilingual foundation models. He designed the multilingual model [Unicoder](https://arxiv.org/abs/1909.00964), which covers 100 languages, and applied this technology to the Bing Search team and Microsoft Translator, significantly improving their understanding of low-resource languages. He also participated in the WMT21 machine translation competition, winning first place globally. In addition, he led the development of [M3P](https://arxiv.org/abs/2006.02635), the world’s first multilingual multimodal pre-trained model. He has published dozens of papers in top conferences such as CVPR, NeurIPS, ACL, EMNLP, and AAAI, with over 2,000 citations on Google Scholar. In 2024, he joined StepFun, leading the development and open-sourcing of the 30B StepVideo model series ([Step-Video-T2V](https://arxiv.org/abs/2502.10248), [Step-Video-TI2V](https://arxiv.org/abs/2503.11251)).

黄浩洋现任京东探索学院图像与多模态实验室资深专家，带领团队开展统一多模态基础模型研究。他拥有北京大学硕士学位，多次获得全球顶级数据挖掘比赛奖项，并获得 Kaggle Master 称号。在微软亚洲研究院，他专注于多模态与多语言基础模型的研究，最早开展多语言基础模型的设计，推出了覆盖 100 种语言的多语言模型 Unicoder，并将相关技术应用于微软必应搜索团队和微软机器翻译，显著提升了对小语种的理解能力，且参与 WMT21 机器翻译比赛获得全球第一名。此外，他还主导了全球首个多语言多模态预训练模型 M3P 的研发。他在 CVPR、NeurIPS、ACL、EMNLP、AAAI 等顶级会议发表了数十篇论文，谷歌学术引用量超过 2,000 次。2024 年，他加入 StepFun，主导并开源了 30B StepVideo 模型系列（Step-Video-T2V、Step-Video-TI2V）。


# Highlights

###  <ul style="text-align: left;">
   <li><strong>
    Multimodal Foundation Model: </strong> <a href="https://arxiv.org/abs/2006.02635" style="color:blue;">M3P</a> (CVPR, 2021), <a href="https://arxiv.org/abs/2002.06353" style="color:blue;">UNIVL</a> (Preprint, 2021), <a href="https://aclanthology.org/2021.acl-long.156/" style="color:blue;">HCN</a> (ACL, 2021), <a href="https://arxiv.org/abs/2202.05009" style="color:blue;">NUWA-LIP</a> (CVPR, 2023), <a href="https://arxiv.org/abs/2502.10248" style="color:blue;">Step-Video-T2V</a> (Technical Report, 2025), <a href="https://arxiv.org/abs/2503.11251" style="color:blue;">Step-Video-TI2V</a> (Technical Report, 2025), <a href="https://arxiv.org/abs/2505.07344" style="color:blue;">GPDiT</a> (Technical Report, 2025)
  </li>  
  <li><strong>Multilingual Foundation Model: </strong> <a href="https://arxiv.org/abs/1909.00964" style="color:blue;">Unicoder</a> (EMNLP, 2019), <a href="https://arxiv.org/abs/2305.07004" style="color:blue;">XLT</a> (EMNLP, 2023), <a href="https://aclanthology.org/2024.naacl-long.367/" style="color:blue;">Div-Ref</a> (NAACL, 2023), <a href="https://aclanthology.org/2024.emnlp-main.55/" style="color:blue;">CoD</a> (EMNLP, 2023), <a href="https://arxiv.org/abs/2402.13064" style="color:blue;">GLAN</a>(EMNLP, 2024), <a href="https://aclanthology.org/2024.acl-long.229/" style="color:blue;">PED</a> (ACL, 2024), <a href="https://arxiv.org/abs/2402.16438" style="color:blue;">LAPE</a>(ACL, 2024)
  </li> 
  <li><strong>Machine Translation:</strong> <a href="https://arxiv.org/abs/2012.15547" style="color:blue;">XLM-T</a> (Preprint, 2020), <a href="https://aclanthology.org/2021.wmt-1.54" style="color:blue;">WMT21 First-Place Report</a> (SIGMT, 2021), <a href="https://aclanthology.org/2021.acl-short.31/" style="color:blue;">MANMT</a> (ACL 2021), <a href="https://aclanthology.org/2022.emnlp-main.184/" style="color:blue;">LVP-M3</a> (EMNLP, 2022)
  </li> 
  </ul>

# Publication


###  <ul style="text-align: left;">
  <li>
    <strong>Generative Pre-trained Autoregressive Diffusion Transformer</strong><br>
    Yuan Zhang, Jiacheng Jiang, Guoqing Ma, Zhiying Lu, Bo Wang, Haoyang Huang, Jianlong Yuan, Nan Duan.<br> 
     NeurIPS, 2025.
  </li>

  <li>
    <strong>Step-Video-Ti2v Technical Teport</strong><br>
    Haoyang Huang, Guoqing Ma, Nan Duan, Xing Chen, Changyi Wan, Ranchen Ming, Tianyu Wang, Bo Wang, Zhiying Lu.<br> 
    Technical Report, 2025.
  </li>

  <li>
    <strong>Step-Video-T2v Technical Teport</strong><br>
    Guoqing Ma, Haoyang Huang, Kun Yan, Liangyu Chen, Nan Duan.<br>
    Technical Report, 2025.
  </li>

  <li>
    <strong>STORYANCHORS: Generating Consistent Multi-Scene Story Frames for Long-Form Narratives</strong><br>
    Bo Wang, Haoyang Huang, Zhiying Lu, Fengyuan Liu, Guoqing Ma, Jianlong Yuan, Yuan Zhang, Nan Duan, Daxin Jiang.<br>
    Preprint, 2025.
  </li>

  <li>
    <strong>Generative pre-trained autoregressive diffusion transformer</strong><br>
    Yuan Zhang, Jiacheng Jiang, Guoqing Ma, Zhiying Lu, Haoyang Huang, Jianlong Yuan, Nan Duan.<br>
    Preprint, 2025.
  </li>

  <li>
    <strong>Respond in my language: Mitigating language inconsistency in response generation based on large language models</strong><br>
    Liang Zhang, Qin Jin, Haoyang Huang, Dongdong Zhang, Furu Wei.<br>
    ACL, 2024.
  </li>

  <li>
    <strong>Language-specific neurons: The key to multilingual capabilities in large language models</strong><br>
    Tianyi Tang, Wenyang Luo, Haoyang Huang, Dongdong Zhang, Xiaolei Wang, Xin Zhao, Furu Wei, Ji-Rong Wen.<br> 
    ACL, 2024.
  </li>

  <li>
    <strong>Synthetic data (almost) from scratch: Generalized instruction tuning for language models</strong><br>
    Haoran Li, Qingxiu Dong, Zhengyang Tang, Chaojun Wang, Xingxing Zhang, Haoyang Huang, Shaohan Huang, Xiaolong Huang, Zeqiang Huang, Dongdong Zhang.<br> 
    EMNLP Finding, 2024.
  </li>

   <li>
    <strong>TRIP: Accelerating Document-level Multilingual Pre-training via Triangular Document-level Pre-training on Parallel Data Triplets</strong><br>
    Hongyuan Lu, Haoyang Huang, Shuming Ma, Dongdong Zhang, Wai Lam, Zhaochuan Gao, Anthony Aue, Arul Menezes, Furu Wei.<br> 
    EMNLP, 2024.
  </li>

   <li>
    <strong>Not All Metrics Are Guilty: Improving NLG Evaluation by Diversifying References</strong><br>
    Tianyi Tang, Hongyuan Lu, Yuchen Jiang, Haoyang Huang, Dongdong Zhang, Xin Zhao, Tom Kocmi, Furu Wei.<br> 
    NAACL, 2024.
  </li>

  <li>
    <strong>Chain-of-Dictionary Prompting Elicits Translation in Large Language Models</strong><br>
    Hongyuan Lu, Haoran Yang, Haoyang Huang, Dongdong Zhang, Wai Lam, Furu Wei.<br> 
    EMNLP, 2024.
  </li>

   <li>
    <strong>Not All Languages Are Created Equal in LLMs</strong><br>
    Haoyang Huang, Tianyi Tang, Dongdong Zhang, Wayne Xin Zhao, Ting Song, Yan Xia, Furu Wei.<br> 
    EMNLP, 2023.
   </li>

  <li>
    <strong>HanoiT: Enhancing Context-aware Translation via Selective Context</strong><br>
    Jian Yang, Yuwei Yin, Shuming Ma, Liqun Yang, Hongcheng Guo, Haoyang Huang, Dongdong Zhang, Yutao Zeng, Zhoujun Li, Furu Wei.<br> 
    DASFFAA, 2023.
   </li>

  <li>
    <strong>NÜWA-LIP: Language Guided Image Inpainting with Defect-free VQGAN</strong><br>
    Minheng Ni, Chenfei Wu, Haoyang Huang, Daxin Jiang, Wangmeng Zuo, Nan Duan.<br> 
    CVPR, 2023.
   </li>

  <li>
    <strong>GanLM: Encoder-Decoder Pre-training with an Auxiliary Discriminator</strong><br>
    Jian Yang, Shuming Ma, Li Dong, Shaohan Huang, Haoyang Huang, Yuwei Yin, Dongdong Zhang, Liqun Yang, Furu Wei, Zhoujun Li.<br> 
    ACL, 2023.
   </li>

  <li>
    <strong>LVP-M3: Language-aware Visual Prompt for Multilingual Multimodal Machine Translation</strong><br>
    Hongcheng Guo, Jiaheng Liu, Haoyang Huang, Jian Yang, Zhoujun Li, Dongdong Zhang, Zheng Cui.<br> 
    EMNLP, 2022.
   </li>

  <li>
    <strong>BlonDe: An Automatic Evaluation Metric for Document-level Machine Translation</strong><br>
    Yuchen Jiang, Tianyu Liu, Shuming Ma, Dongdong Zhang, Jian Yang, Haoyang Huang, Rico Sennrich, Ryan Cotterell, Mrinmaya Sachan, Ming Zhou.<br> 
    NAACL, 2022.
   </li>

   <li>
    <strong>M3P: Learning Universal Representations via Multitask Multilingual Multimodal Pre-training</strong><br>
    Minheng Ni, Haoyang Huang, Lin Su, Edward Cui, Taroon Bharti, Lijuan Wang, Dongdong Zhang, Nan Duan.<br> 
    CVPR, 2021.
   </li>

   <li>
    <strong>UniVL: A Unified Video and Language Pre-Training Model for Multimodal Understanding and Generation</strong><br>
    Huaishao Luo, Lei Ji, Botian Shi, Haoyang Huang, Nan Duan, Tianrui Li, Jason Li, Taroon Bharti, Ming Zhou.<br> 
    Preprint, 2021.
   </li>
   

   <li>
    <strong>Hierarchical Context-aware Network for Dense Video Event Captioning</strong><br>
    Lei Ji, Xianglin Guo, Haoyang Huang, Xilin Chen.<br> 
    ACL, 2021.
   </li>

   <li>
    <strong>Xgpt: Cross-modal generative pre-training for image captioning</strong><br>
    Qiaolin Xia, Haoyang Huang, Nan Duan, Dongdong Zhang, Lei Ji, Zhifang Sui, Edward Cui, Taroon Bharti, Ming Zhou.<br> 
    NLPCC, 2021.
   </li>

   <li>
    <strong>Multilingual Agreement for Multilingual Neural Machine Translation</strong><br>
    Jian Yang, Yuwei Yin, Shuming Ma, Haoyang Huang, Dongdong Zhang, Zhoujun Li, Furu Wei.<br> 
    ACL, 2021.
   </li>

   <li>
    <strong>Improving Multilingual Neural Machine Translation with Auxiliary Source Languages</strong><br>
    Weijia Xu, Yuwei Yin, Shuming Ma, Dongdong Zhang, Haoyang Huang.<br> 
    EMNLP finding, 2021.
   </li>

   <li>
    <strong>Multilingual Machine Translation Systems from Microsoft for WMT21 Shared Task</strong><br>
    Jian Yang, Haoyang Huang, Shuming Ma, Dongdong Zhang, Li Dong, Shaohan Huang, Alexandre Muzio, Saksham Singhal, Hany Hassan, Xia Song, Furu Wei.<br> 
    SIGMT, 2021.
   </li>

   <li>
    <strong>XLM-T: Scaling up Multilingual Machine Translation with Pretrained Cross-lingual Transformer Encoders</strong><br>
    Shuming Ma, Jian Yang, Haoyang Huang, Zewen Chi, Li Dong, Dongdong Zhang, Hany Hassan Awadalla, Alexandre Muzio, Akiko Eriguchi, Saksham Singhal, Xia Song, Arul Menezes, Furu Wei.<br> 
    Arxiv, 2020 .
   </li>

   <li>
    <strong>Unicoder: A Universal Language Encoder by Pre-training with Multiple Cross-lingual Tasks</strong><br>
    Haoyang Huang, Yaobo Liang, Nan Duan, Ming Gong, Linjun Shou, Daxin Jiang, Ming Zhou.<br> 
    EMNLP, 2019.
   </li>

</ul>
